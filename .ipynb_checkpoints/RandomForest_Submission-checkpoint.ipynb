{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1, 1, 1, 1, 0]\n",
    "B = [1, 1, 0, 0, 0]\n",
    "C = [1, 0, 1, 0, 1]\n",
    "D = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(A):\n",
    "    n = len(A)\n",
    "    result = [0, 0]\n",
    "    for coin in range(2):        \n",
    "        for i in range(n - 1):\n",
    "            if (A[i] == A[i + 1] and A[i] == coin):\n",
    "                result[coin] = result[coin] + 1\n",
    "        result[coin] = result[coin] + 1\n",
    "    #print(\"gleiche Nachbarcoins:\", result[0], result[1])\n",
    "    #print()\n",
    "    r = [0, 0]\n",
    "    for coin in range(2):    \n",
    "        for i in range(n):\n",
    "            count = 0\n",
    "            if (i > 0 and A[i] == coin):\n",
    "                #print(\"i>0, i=\", i)\n",
    "                if (A[i - 1] != A[i]):\n",
    "                    count = count + 1\n",
    "                    #print(\"count=\", count)\n",
    "                #else:\n",
    "                #    count = count - 1\n",
    "                    #print(\"else\", i, \"count=\", count)\n",
    "            if (i < n - 1 and A[i] == coin):\n",
    "                #print(\"i<n-1, i = \",i)\n",
    "                if (A[i + 1] != A[i]):\n",
    "                    count = count + 1\n",
    "                    #print(\"count=\", count)\n",
    "                #else:\n",
    "                #    count = count - 1\n",
    "                    #print(\"else\", i, \"count=\", count)\n",
    "            r[coin] = max(r[coin], count)\n",
    "        #print(r[coin])\n",
    "    #print(result[0], r[0], result[1],  r[1])\n",
    "    return max(result[0] + r[1], result[1] + r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(A):\n",
    "    n = len(A)\n",
    "    result = 0\n",
    "    for i in range(n - 1):\n",
    "        if (A[i] == A[i + 1]):\n",
    "            result = result + 1\n",
    "    print(result)\n",
    "    r = 0\n",
    "    for i in range(n):\n",
    "        count = 0\n",
    "        if (i > 0):\n",
    "            if (A[i - 1] != A[i]):\n",
    "                count = count + 1\n",
    "            else:\n",
    "                count = count - 1\n",
    "        if (i < n - 1):\n",
    "            if (A[i + 1] != A[i]):\n",
    "                count = count + 1\n",
    "            else:\n",
    "                count = count - 1\n",
    "        r = max(r, count)\n",
    "    return result + r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in training set and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete columns wich contain string values.\n",
    "\n",
    "Create training set where columns with missing values are dropped and where they are imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Read the data\n",
    "train = pd.read_csv('original/train.csv')\n",
    "#train.head(n=3)\n",
    "###### Exclude non numeric values\n",
    "train = train.select_dtypes(exclude=['object'])\n",
    "# drop 43 columns (81 -38)\n",
    "###### Drop columns with missing values\n",
    "cols_na = [col for col in train.columns \n",
    "                                 if train[col].isnull().any()]\n",
    "train_nona = train.drop(cols_na, axis=1)\n",
    "#train_nona = train.dropna(axis=1)\n",
    "###### \n",
    "#train.shape, train_nona.shape\n",
    "# 3 columns dropped, 38 -> 35\n",
    "\n",
    "###### Make default imputations\n",
    "my_imputer = Imputer()\n",
    "train_impute = my_imputer.fit_transform(train)\n",
    "train_impute = pd.DataFrame(train_impute)\n",
    "train_impute.columns = train.columns\n",
    "#train_nona.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for NaN values in test set and delete columns in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test data\n",
    "test = pd.read_csv('original/test.csv')\n",
    "###### Exclude non numeric values\n",
    "test = test.select_dtypes(exclude=['object'])\n",
    "### Drop columns with non numeric entries and missing values\n",
    "test_nona = test[train_nona.columns[0:34]]\n",
    "#### Look for missing values\n",
    "#print(test_nona.isnull().sum())\n",
    "###### Drop columns with missing values\n",
    "cols_na = [col for col in test_nona.columns \n",
    "                                 if test_nona[col].isnull().any()]\n",
    "test_nona = test_nona.drop(cols_na, axis=1)\n",
    "train_nona = train_nona.drop(cols_na, axis=1)\n",
    "#test_nona.shape, train_nona.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute values in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Impute values in test data\n",
    "test_impute = my_imputer.fit_transform(test)\n",
    "test_impute = pd.DataFrame(test_impute)\n",
    "test_impute.columns = test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find good parameters on training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "y_nona = train_nona.SalePrice\n",
    "X_nona = train_nona.drop(['SalePrice'], axis=1)\n",
    "########\n",
    "y_impute = train_impute.SalePrice\n",
    "X_impute = train_impute.drop(['SalePrice'], axis=1)\n",
    "########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what parameters to change\n",
    "\n",
    "in randomforestregressor ?\n",
    "\n",
    "in columns for prediction ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## score dataset\n",
    "def calc_mae(X, y, seed):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)\n",
    "    # run ml\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(train_X, train_y)\n",
    "    # pred values\n",
    "    pred_val = model.predict(val_X)\n",
    "    # calc accuracy\n",
    "    mae = mean_absolute_error(val_y, pred_val)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20968.579093150685, 19645.275191780816)\n"
     ]
    }
   ],
   "source": [
    "max = 100\n",
    "mae1 = 0\n",
    "mae2 = 0\n",
    "for i in range (0, max):\n",
    "    mae1 = mae1 + calc_mae(X_nona, y_nona, i)\n",
    "    mae2 = mae2 + calc_mae(X_impute, y_impute, i)\n",
    "print(max,mae1/max, mae2/max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Final model on whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull data into target (y) and predictors (X)\n",
    "train_y = train_impute.SalePrice\n",
    "#predictor_cols = ['LotArea', 'OverallQual', 'YearBuilt', 'TotRmsAbvGrd']\n",
    "\n",
    "# Create training predictors data\n",
    "train_X = train_impute.drop(['SalePrice'], axis=1)\n",
    "#train_X = train_impute[predictor_cols]\n",
    "\n",
    "my_model = RandomForestRegressor()\n",
    "my_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in test set, make predictions and write values to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 133550.  156050.  184490. ...,  158690.  105790.  240700.]\n"
     ]
    }
   ],
   "source": [
    "# Treat the test data in the same way as training data. In this case, pull same columns.\n",
    "#test_X = test[predictor_cols]\n",
    "test_X = test_impute\n",
    "# Use the model to make predictions\n",
    "predicted_prices = my_model.predict(test_X)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "print(predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
