{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in training set and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete columns wich contain string values.\n",
    "\n",
    "Create training set where columns with missing values are dropped and where they are imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Read the data\n",
    "train = pd.read_csv('original/train.csv')\n",
    "#train.head(n=3)\n",
    "###### Exclude non numeric values\n",
    "train = train.select_dtypes(exclude=['object'])\n",
    "# drop 43 columns (81 -38)\n",
    "###### Drop columns with missing values\n",
    "cols_na = [col for col in train.columns \n",
    "                                 if train[col].isnull().any()]\n",
    "train_nona = train.drop(cols_na, axis=1)\n",
    "#train_nona = train.dropna(axis=1)\n",
    "###### \n",
    "#train.shape, train_nona.shape\n",
    "# 3 columns dropped, 38 -> 35\n",
    "\n",
    "###### Make default imputations\n",
    "my_imputer = Imputer()\n",
    "train_impute = my_imputer.fit_transform(train)\n",
    "train_impute = pd.DataFrame(train_impute)\n",
    "train_impute.columns = train.columns\n",
    "#train_nona.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for NaN values in test set and delete columns in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test data\n",
    "test = pd.read_csv('original/test.csv')\n",
    "###### Exclude non numeric values\n",
    "test = test.select_dtypes(exclude=['object'])\n",
    "### Drop columns with non numeric entries and missing values\n",
    "test_nona = test[train_nona.columns[0:34]]\n",
    "#### Look for missing values\n",
    "#print(test_nona.isnull().sum())\n",
    "###### Drop columns with missing values\n",
    "cols_na = [col for col in test_nona.columns \n",
    "                                 if test_nona[col].isnull().any()]\n",
    "test_nona = test_nona.drop(cols_na, axis=1)\n",
    "train_nona = train_nona.drop(cols_na, axis=1)\n",
    "#test_nona.shape, train_nona.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute values in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Impute values in test data\n",
    "test_impute = my_imputer.fit_transform(test)\n",
    "test_impute = pd.DataFrame(test_impute)\n",
    "test_impute.columns = test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find good parameters on training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "y_nona = train_nona.SalePrice\n",
    "X_nona = train_nona.drop(['SalePrice'], axis=1)\n",
    "########\n",
    "y_impute = train_impute.SalePrice\n",
    "X_impute = train_impute.drop(['SalePrice'], axis=1)\n",
    "########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what parameters to change\n",
    "\n",
    "in randomforestregressor ?\n",
    "\n",
    "in columns for prediction ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## score dataset\n",
    "def calc_mae(X, y, seed):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)\n",
    "    # run ml\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(train_X, train_y)\n",
    "    # pred values\n",
    "    pred_val = model.predict(val_X)\n",
    "    # calc accuracy\n",
    "    mae = mean_absolute_error(val_y, pred_val)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20968.579093150685, 19645.275191780816)\n"
     ]
    }
   ],
   "source": [
    "max = 100\n",
    "mae1 = 0\n",
    "mae2 = 0\n",
    "for i in range (0, max):\n",
    "    mae1 = mae1 + calc_mae(X_nona, y_nona, i)\n",
    "    mae2 = mae2 + calc_mae(X_impute, y_impute, i)\n",
    "print(max,mae1/max, mae2/max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Final model on whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull data into target (y) and predictors (X)\n",
    "train_y = train_impute.SalePrice\n",
    "#predictor_cols = ['LotArea', 'OverallQual', 'YearBuilt', 'TotRmsAbvGrd']\n",
    "\n",
    "# Create training predictors data\n",
    "train_X = train_impute.drop(['SalePrice'], axis=1)\n",
    "#train_X = train_impute[predictor_cols]\n",
    "\n",
    "my_model = RandomForestRegressor()\n",
    "my_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in test set, make predictions and write values to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 129750.  154065.  168200. ...,  162900.  114090.  232529.]\n"
     ]
    }
   ],
   "source": [
    "# Treat the test data in the same way as training data. In this case, pull same columns.\n",
    "#test_X = test[predictor_cols]\n",
    "test_X = test_impute\n",
    "# Use the model to make predictions\n",
    "predicted_prices = my_model.predict(test_X)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "print(predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
